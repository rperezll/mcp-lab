# MCP Lab

Este repositorio es un laboratorio personal donde he estado trasteando con el SDK de [**Model Context Protocol**](https://modelcontextprotocol.io/introduction) ([@modelcontextprotocol/sdk](https://github.com/modelcontextprotocol/typescript-sdk)) usando TypeScript. La idea principal es entender bien c贸mo funciona el protocolo, hacer pruebas r谩pidas y montar casos de uso m谩s reales seg煤n me iba sintiendo c贸modo con la herramienta.

## Estructura del proyecto

```text
.
  mcp-server-dummies/   # Primeros pasos usando el SDK de MCP.
  mcp-lab-text2sql/     # Caso de uso avanzado: Text-to-SQL sobre una base de datos SQLite.
```

## И mcp-server-dummies

Este proyecto contiene una implementaci贸n b谩sica para familiarizarse con el SDK de MCP. Fue pensado como un primer acercamiento al protocolo, 煤til para pruebas simples y entender su funcionamiento (nada sofisticado).

### Instalaci贸n

> [!NOTE] 
> El proyecto requiere una versi贸n de Node.js >= v20.

```bash
cd mcp-server-dummies
npm i
```

### Ejecuci贸n

```bash
npm run build     # Compila el proyecto con tsc
npm run dev       # Ejecuta el servidor con ts-node
```

Como herramienta de depuraci贸n, podemos utilizar el siguiente comando, que lanza el [**MCP Inspector**](https://github.com/modelcontextprotocol/inspector). Esta utilidad proporciona una interfaz visual para probar y depurar nuestro servidor MCP de forma m谩s c贸moda e interactiva.

```bash
npm run test
```

El comando nos expone el inspector en [http://localhost:6274](http://localhost:6274) asociado a nuestro servidor MCP.

##  mcp-lab-text2sql

Este segundo proyecto implementa un sistema de Text-to-SQL: se puede chatear con una base de datos SQLite utilizando lenguaje natural. Este servidor MCP expone las herramientas y recursos necesarios para que nuestro LLM sea capaz de chatear con nuestros datos.

### Instalaci贸n

> [!NOTE] 
> El proyecto requiere una versi贸n de Node.js >= v20.

```bash
cd mcp-server-dummies
npm i
```

### Ejecuci贸n

```bash
npm run build     # Compila el proyecto con tsc
npm run dev       # Ejecuta el servidor con ts-node
```

Como herramienta de depuraci贸n, podemos utilizar el siguiente comando, que lanza el [**MCP Inspector**](https://github.com/modelcontextprotocol/inspector). Esta utilidad proporciona una interfaz visual para probar y depurar nuestro servidor MCP de forma m谩s c贸moda e interactiva.

```bash
npm run test
```

El comando nos expone el inspector en [http://localhost:6274](http://localhost:6274) asociado a nuestro servidor MCP.

## Claude Desktop

Podemos probar nuestros servidores MCP desde [**Claude Desktop**](https://claude.ai/download). Para asociar nuestros servidores MCP debemos modificar el archivo `claude_desktop_config.json` de la siguiente manera:

```json
{
    "mcpServers": {
        "mcp-lab-dummies": {
            "command": "node",
            "args": [
                "C://PATH//mcp-lab//mcp-server-dummies//dist//index.js"
            ]
        },
        "mcp-lab-text2sql": {
            "command": "node",
            "args": [
                "C://PATH//mcp-lab//mcp-server-text2sql//dist//index.js"
            ]
        }
    }
}
```

> [!IMPORTANT] 
> Recuerda ejecutar `npm run build` dentro de cada proyecto previamente.

驴D贸nde se encuentra `claude_desktop_config.json` en Windows? ★ `PATH//AppData//Roaming//Claude`.

Para conocer m谩s sobre la sintaxis y ubicaci贸n de este archivo de configuraci贸n usa la [documentaci贸n oficial](https://modelcontextprotocol.io/quickstart/user).

## Compatibilidad con OpenAI

Usar servidores MCP con OpenAI funciona bien cuando se trata de Tools. Pero si lo que queremos es consumir Recursos, todo se vuelve m谩s complejo.

> [!IMPORTANT]
> Ojo: se pueden usar servidores MCP de forma nativa con el SDK de agentes de OpenAI, aunque por ahora ese SDK solo est谩 disponible en Python. En mi caso, las pruebas las estoy haciendo con el SDK de OpenAI para TypeScript, usando la Responses API.

Vale... tengo mi servidor MCP que expone varias Tools usables desde Claude Desktop. Hasta ah铆 todo perfecto. Pero ahora me pregunto: 驴puedo usar ese mismo servidor MCP en un agente que funciona con la API de OpenAI?

En primera instancia usar modelos GPT y conectarlos a nuestro MCP Server no es compatible. La definci贸n de Tool de **@modelcontextprotocol** y **OpenAI** son diferentes. 驴Quiere decir que no lo puedo utilizar? No exactamente. Vamos a construir un MCP Client que habilite esta integraci贸n.

> [!IMPORTANT]
> Esta especificaci贸n es compatible con la versi贸n `4.95.0` del **SDK de OpenAI para TypeScript** y la versi贸n `1.9.0` de **@modelcontextprotocol/sdk**.

Tipo devuelto por la funci贸n **getTools()** de nuestro Cliente MCP:

```ts
import { Tool } from "@modelcontextprotocol/sdk/types.js";

const mcpTool: Tool = {
  name: "getUser",
  description: "Get a user by ID",
  inputSchema: z.object({
    type: z.literal("object"),
    properties: z.object({
      id: z.string()
    })
  })
}
```

Tipo que espera la **Response API de OpenAI** para trabajar con tools:

[Documentaci贸n OpenAI](https://platform.openai.com/docs/guides/function-calling?api-mode=responses)

```ts
import OpenAI from "openai";

// El campo "parameters" es un JSON Schema

const openaiTool: OpenAI.Responses.Tool {
  "type": "function",
  "name": "getUser",
  "description": "Get a user by ID",
  "parameters": {
    "type": "object",
    "properties": {
      "id": { "type": "string" }
    },
    "required": ["id"],
    "additionalProperties": false
  },
  "strict": true
}
```

### Limitaciones

Cuando configuramos nuestra Tool en el servidor MCP debemos tener en cuenta algunas opciones **no compatibles con OpenAI**, a la hora de tipar nuestros argumentos usando Zod:

Todos los par谩metros deben ser **requeridos**:
```text
Invalid schema for function 'update-user-goal': In context=(), 'required' is required to be supplied and to be an array including every key in properties.
```

No podemos usar **max()** o **min()** a la hora de definir un campo int():
```text
Invalid schema for function 'update-user-goal': In context=('properties', 'age', 'anyOf', '0'), 'minimum|maximun' is not permitted.
```

No podemos usar **default()** para establecer valores por defecto:
```text
BadRequestError: 400 Invalid schema for function 'update-user-goal': In context=('properties', 'hasPaid', 'anyOf', '0'), 'default' is not permitted.
```

### Demo *test*

Ejecuta la demo con un Agente LLM usando OpenAI.

1. Ejecuta `npm run build` dentro del directorio **mcp-server-dummies** ya que ese es el MCP Server que vamos a utilizar.

2. Instala las dependencias con `npm i`, dentro del directorio **mcp-client**.

3. Ejecuta la demo, en el directorio **mcp-client**, usando el comando `npm run dev`.

- No olvides crear tu `.env`, dentro de **mcp-client**, con tu API Key v谩lida de OpenAI:

  ```env
  OPENAI_API_KEY=<openai_key>
  ```


##  Licencia

**MIT 漏 [rperezll](https://github.com/rperezll)**